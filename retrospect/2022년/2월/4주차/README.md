# (기술) 인공지능

최근 사업 계획서나, 새로운 사업 구상을 할 때 거의 모든 분야에서 사업의 기술성을 증명하기 위한 수단으로 빅데이터, 클라우드 등과 4차 산업혁명을 이끈다고 봐도 무방한 인공지능이 언급되곤 한다. 이렇게 자주 언급되는 데에 비해 실제로 인공지능에 대한 이미지가 "뭔지는 모르지만 엄청 대단한 것.", "인공지능 로봇으로 혁신적인 변화를 가져다주는 것." 여기서 조금 내용을 들어본 사람은 "많은 데이터를 학습시켜서 이용하는 것." 정도로 인식할 수 있는데, 어느정도 정리해두면 좋을 것 같다는 생각이 들어 조사를 해보았다.

> 하위 내용은 모두 내 스스로 이해하고 작성한 것이므로 100% 정확하지 않음을 유의하고 읽으면 좋을 것 같다.

## 인공지능의 언어

우선 인공지능이 어렵게 느껴지는 이유는 대부분의 용어가 학술 용어 출신이라 생소하기 때문이다.  
인공지능을 어느정도 접해본 사람은 "기계 학습", "머신 러닝", "딥 러닝"이라는 존재를 알고 있는데, 이를 통해 **"학습"**이라는 키워드가 인공지능에서 중요한 요소라는 것은 쉽게 유추할 수 있다. 하지만 이것만으로는 인공지능이 어떻게 학습을 하고, 무엇을 학습을 하여 어떤 것을 배우는지는 알지 못한다.  
따라서 우선 이러한 큰 틀의 대한 용어부터 알아야 할 필요성이 있다.

- 인공지능(`AI`, `Artificial Intelligence`): 인간이 지닌 지적 능력의 일부 또는 전체, 혹은 그렇게 생각되는 능력을 인공적으로 구현한 가장 큰 범주의 용어로, 흔히 말하는 **기술의 이름** 그 자체이다.
- 기계 학습(`Machine Learning`): 어떤 작업 `T`에 대해 꾸준한 경험 `E`를 통하여 `T`에 대한 성능 `P`를 높이는 것으로, 컴퓨터를 인간처럼 학습시켜 스스로 규칙을 형성하는 **방법론**이다.
- 인공 신경망(`ANN`, `Artificial Neural Network`): 소프트웨어적으로 인간의 뉴런 구조를 본떠 만든 기계 학습의 모델로, 생물의 신경망, 특히 인간의 시각/청각 피질을 본떠 만든 **알고리즘**이다.
- 딥 러닝(`Deep Learning`, 심층 학습): 다층 인공 신경망 기법으로, 인공 뉴런들을 여러 개 층층이 쌓고 연결한 **인공 신경망 기법** 중 하나이다.

즉, 위에서부터 아래로 포괄하는 개념으로, 이 아래에도 다양한 용어들이 무수히 많다.

## 인공지능

인공지능은 크게 **강인공지능**과 **약인공지능**으로 구분할 수 있는데 강인공지능은 인간을 완벽하게 모방한 인격체로서의 인간 그 자체와 동일한 수준을 말하고, 약인공지능은 유용한 도구로써 설계된 인공지능을 말한다.

놀랍게도 인공지능이라는 개념 자체는 관련 영화 등의 작품을 다루기도 훨씬 이전부터 논의되고 있었지만, 본격적으로 발달된 것은 컴퓨터의 발전과 함께 학문으로 여겨지면서부터였다. 그만큼 오래된 학문이고, 과거부터 자연어 처리나 복잡한 수학 문제를 해결하는 등의 기술력이 있었으며, 최근 들어 각광 받고 사용되고 있기 때문에 굉장히 발전한 기술이라고 생각할 수 있는데 실상은 그렇지 않다. 그냥 원래 있던게 우수해졌을 뿐이고, 실제 뇌의 작동 원리에 대한 연구조차 제대로 진행되지 않았기 때문에 강인공지능과는 거리가 먼 상태이다.

인공지능이라는 말만 들어가면 신뢰도 및 기술성이 급상승하는 것처럼 보이는 경향이 있는데, 사실 그 정도의 기술은 아니고 그냥 엄청나게 발전한 컴퓨터 성능에 수많은 알고리즘(생각할 수 있는 분기점)을 탑재하여 동작하는 약인공지능에 불과하다.

따라서 과거 매체나 미디어로 접했던 인공지능 로봇이 지구를 정복한다거나, 서버에 있는 인공지능이 스스로 학습하여 전 세계 서버를 해킹하여 통제하는 상황은 현재로서는 절대 발생하지 않는다. 그리고 이건 개인적인 생각인데 아마 현존하는 이진 컴퓨터(`0`과 `1`로 이루어진)로는 절대 인간의 뇌를 표방하거나, 인공지능 로봇이 지구를 정복할만큼의 기술력이나 연산 처리 능력이 갖춰질 거라고는 생각되지 않는다. 인간의 뇌가 이진 컴퓨터 방식으로 동작하지 않아 사실상 매커니즘 자체가 다르기 때문이다. 만에 하나 뇌에 대한 연구 결과로 뇌의 뉴런이 `0`과 `1` 두 이진 데이터만으로 정보를 통해 전달을 한다고 밝혀지지 않는 이상.

그렇다고 해서 전망 없는 기술은 아닌 것이, 인공지능이 동작하는 컴퓨터는 인간과 비교했을 때 압도적인 계산 속도, 기억 능력, 정확성, 근면성 등의 장점을 가지고 있다. 현대의 인공지능이 이를 활용할 수 있는 수단을 잘 찾아내어 사용 중이기 때문에 각광 받고 있다.

## 기계 학습

기존의 인공지능은 사람이 직접 수많은 규칙을 하나하나 집어 넣는 것을 전제로 하였다. 가령 스타크래프트라는 게임의 적군 혹은 아군으로 출현시킬 수 있는 봇(컴퓨터 플레이어)는, 현재 상황 및 유닛, 자원의 상태를 주기적으로 확인하여 그때 그때 어떤 행동을 취해야 할 지가 모두 입력이 되어 있다. 따라서 플레이어가 어떤 돌발 행동을 하면 봇이 아무 행동을 하지 않는다던가, 봇이 한 20분 이상 플레이하면 더이상 공격적인 플레이를 진행하지 않는다거나 하는 현상이 발생하곤 했다.

시간이 지남에 따라 음성 인식과 같은 규칙을 집어 넣는 방법으로는 도저히 구현할 수 없는 프로그램을 요구하게 되었고, 매우 통계적인 접근 방법인 기계 학습이 사용되기 시작했다.

기계 학습은 인간이 하는 추론 방식과 유사하며, 위의 규칙을 집어넣는 예시와 반대로, 어떤 행동을 취해야 할 지를 찾아내는 것이 아닌, 현재 시간, 자신의 종족, 자원의 양, 상대방의 상황과 동일한 상황 여러 번을 경험하고, 이 상황에서 어떠한 선택을 했을 때 목적(승리)를 취할 확률이 높은 지를 학습하여 행동하는 **알고리즘을 작성하는 방법론**이다. 따라서 개발자가 직접 규칙을 하나하나 집어 넣어줄 필요가 없으며, 규칙의 변화가 생기더라도 무용지물이 되는 현상이 발생하지 않을 뿐더러, 규칙의 갯수에 대한 한계도 극복할 수 있다.

간단하게 생각하면 인간의 사고를 모방하는 방법으로, 기억하고 축약하며 깨우쳐 이해하기라고 생각할 수 있다.

> 지금의 거의 모든 인공지능이 빠르고 만족스러운 결과를 선보이기 위해 사용하는 방법론이다.

기계학습에도 여러가지 알고리즘이 있는데, 간단한 설명만 하고 자세한 내용은 대부분 수학적인 내용이므로 따로 기회가 되면 조사를 해보도록 할 것이다.

1. 경사/기울기 하강법(`Gradient Descent`)

   - 쉽게 생각하면 어떠한 이미지가 있고 이 이미지가 어떤 이미지인지 밝혀내는 인공지능이 있을 때, 정답이 강아지인 이미지에 고양이라고 답하면 `-1`, 강아지라고 답하면 `+1`하는 방식으로 정확한 답을 선택하도록 수렴시키는 방법이다.

2. 회기 기법

   - 여기에 인공신경망이 포함되며, 인공신경망이 깊으면 딥 러닝이라고도 한다.

3. 확률 기반

   - 확률 기반은 대부분 베이즈 정리에 기반하며, 조건부 확률. 즉, `X`가 주어졌을 때 `Y`가 발생할 확률을 통해 추정하는 방법이다.

4. 기하 기반

5. 앙상블 기반

기계 학습에는 흔히 그래픽 카드(그래픽 카드는 병렬 처리를 하므로 기계학습에 알맞은 계산을 하는데 좋은 성능을 발휘)가 쓰이며, 자연 언어 처리(음성 인식, `TTS`, 형태소 분석 및 구문 분석, 검색), 패턴 인식, 데이터 마이닝, 업무 자동화(맞춤형 고객 응대 챗봇), 신용 평가, 준법 감시, 화질 복구 등에 주로 사용된다.

## 인공 신경망

인공 신경망은 위의 기계 학습 기법 중 회기 기법으로 오래된 학문이지만 다른 기법에 밀려서 하락세였으나, 학자들이 연구함과 동시에 하드웨어 성능이 발전하면서 빛을 보게된 케이스이다.

기본 원리는 단순한데, 그냥 결과를 계산하는(목적을 달성하기 위한 선택을 결정하는) 분기(세포)를 여러 개 만들어서 첫 번째 분기에 넣은 결과를 두 번째 분기에 다시 넣는 방식으로, 여러 번 거쳐 곱 씹으며 결과를 도출하는 방식이다.

여기서 학습이 필요한 부분은 그런 결과를 계산하는 분기들의 수식이다. 초기에 무작위로 계산하는 세포들이 자신들이 계산한 결과와 실제 목적 결과를 계속해서 비교해가며 끊임없이 조정해가는 것이다. 따라서 학습하지 않는 신경망은 거의 무의미하다고 볼 수 있으며 세포를 **퍼셉트론(`Perceptron`)**, 데이터 레이블-명시적인 정답이 주어진 상태에서 컴퓨터를 학습 시키는 것을 지도 학습이라고 한다.  
지도 학습에서 데이터 레이블-명시적인 정답이 있는 데이터를 훈련 집합, 레이블이 지정되어 있지 않은 검증 집합이라고 하며 이 들을 적절하게 배치, 학습 시켜 정밀도를 조절할 수 있는데, 너무 많은 훈련 집합만을 사용해도 정밀도가 떨어지고, 반대로 검증 집합을 너무 많이 사용해도 정밀도가 떨어진다.

학습을 진행할 때 한 번에 크게 업데이트 하는 것이 아니라, 조금씩 여러 번 업데이트를 하게 되는데, 한 번에 크게 한다고 해서 장기적으로 봤을 때 오차를 줄이는 방법은 아닐 수 있기 때문이다. 그래서 적절한 학습률로 업데이트 하지 않으면 인공 신경망이 틀어지거나, 학습하는데 너무 오래 걸리는 등의 문제가 발생할 수도 있다.

아키텍쳐를 통해 분류하면 단층 퍼셉트론(`Single-Layer Perceptron`), **다층 퍼셉트론(`Multi-Layer Perceptron`, `MLP`)**, **딥 러닝**으로 구분할 수 있으며 학습 방식을 통해 분류하면 지도학습, 강화학습 등으로 구분할 수 있다.

> 일반적으로 인공신경망이라고 하면 대부분 딥 러닝을 칭한다.

일반 프로그램에 비해 높은 사양을 요구하며, 데이터를 정제하는데 사람의 손이 많이 들어가는 등의 노가다 필요하지만, 초기 구현 자체는 오픈 소스 라이브러리가 매우 활성화되어 있어 내부 알고리즘의 조작이 깊게 들어가지 않는 이상 구현은 쉽다는 장점이 있다.

## 딥 러닝

인공신경망 자체는 꽤 오래전부터 존재해왔고 당시의 컴퓨터 연산 성능으로는 사용 가능한 모델 구현이 불가능한 이론적인 방법으로만 여겨졌지만, 컴퓨터의 발달로 가능성을 모색하게 된 방법이다.

딥 러닝의 가장 큰 특징은 모델의 부피를 키우고, 데이터를 쏟아 부으면 무조건적으로 그만큼의 성능 향상을 보인다는 점이다.

높으신 분들에게서 뭐든지 다 할 수 있는 마법의 기술처럼 취급되는 경향이 있으나, 기계 학습으로 여러 개의 모아둔 값에서 가장 많은 것을 또 오차 계산해서 역계산, 조금씩 수정해서 정확한 윤곽을 만드는 기술로, 기계 학습으로 학습한 가장 빈도 수가 많은 값에 오차 보정 알고리즘을 더했다고 보면 된다.

> 인공지능 자체가 결국 어떠한 질문에 대해, 해당 질문이 참인지 거짓인지를 분별할 수 있는 경계 값을 학습을 통해 계속 조정, 설정하고, 사용 시 현재 어떠한 상태에서 해당 질문에 대한 답으로 정답을 도출할 확률을 높이는 과정이다.

그러나 실제로 사용하기 매우 어려운 기술로, 사용할 때는 왜 그렇게 나오는 지에 대한 과정 및 수식, 수식을 작성한 이유 등이 중요한데, 딥 러닝은 블랙박스형 알고리즘이라 이해하고 설명하기 어렵기 때문이다.

알파고는 바둑승률에 대한 역대 기보 데이터를 찾아 학습하고, 바둑의 행렬 위치 별 다양한 기보 속에서 학습한 결과에 대한 승률을 계산하여, 승률이 가장 높은 위치 값에 바둑 알을 놓는 방식으로 구현한 것이다.

자율 주행 자동차의 딥 러닝 학습은 이미지 학습에 의한 사물 인지와, 사물 속도(위치변화/시간), 주행 차량 속도 3가지 큰 영역으로 나누고 1초 뒤, 5초 뒤를 선 예측한 후, 가장 안정적인 방법으로 사물 회피를 통해 안정적 주행을 위한 핸들링, 속도 제어를 하는 것이다.  
이런 방법으로 인해 레이더, 라이더 센서 등 거리를 측정하는 센서가 따로 없이 오직 카메라 센서만으로 자율 주행 구현이 가능하다.  
크게 보면 이미지 학습과 인지 쪽에 인공지능이 많이 연계되어 있고, 나머지 주행 영역은 예측 제어 영역이다.

딥 러닝의 종류로 유명한 것은 `CNN`(`Convolutional Neural Network`, 합성곱 신경망), `RNN`(`Recurrent Neural Network`, 순환 신경망), `Transformer`(트랜스포머)가 있다.  
`CNN`은 이미지 분류 등의 컴퓨터 비전 분야에서 사용되는 기술이며, `RNN`은 문맥 다음에 나올 단어를 예측하는 문제(음성 인식, 필기체 인식, 텍스처 인식)에 유리하며, 분류인 기계 번역 등에도 유리하다.
`RNN`의 개선 버전으로 `LSTM`(`Long Short Term Memory`, 장단기 기억 신경망)도 있다.  
마지막으로 `Transformer`는 자연어 처리 분야에서 활약하다 이미지 분류 등의 컴퓨터 비전 분야를 넘어 현재 아주 다양한 분야에서 활약하는 최신 딥 러닝이다.

## 빅 데이터와의 관계

인공지능과 빅 데이터는 매우 밀접한 관계를 가지고 있다.

인공지능은 학습이 중요하고, 딥 러닝은 데이터를 쏟아 부을 수록 성능 향상이 된다고 해서 빅 데이터를 그대로 가져다 쓰는 뜻으로 이해를 할 수가 있는데, 빅 데이터는 방대한 양의 데이터를 관리하고 분석해서 유용한 정보를 사용하는 기술을 의미한다. 빅 데이터가 데이터를 의미하는 것이 아니라, 데이터를 관리하고 분석하는 기술을 의미하므로, 데이터 관리 기술과 데이터 분석 기술 모두를 포함한다. 인공지능은 여기서 데이터 분석하는 기술로 사용되기 때문에, 인공지능은 빅 데이터를 사용한다라는 말보다는, 빅 데이터를 학습 데이터로 가공하여 인공지능의 학습 재료로 사용한다. 라고 표현하는게 좀 더 알맞을 것 같다.
